{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["X = np.array([\n","    [0, 0, 0, 0],\n","    [0, 0, 0, 1],\n","    [0, 1, 0, 1],\n","    [0, 1, 1, 0],\n","    [0, 0, 0, 0],\n","    [1, 0, 0, 0],\n","    [1, 0, 0, 1],\n","    [1, 1, 1, 1],\n","    [1, 0, 1, 2],\n","    [1, 0, 1, 2],\n","    [2, 0, 1, 2],\n","    [2, 0, 1, 1],\n","    [2, 1, 0, 1],\n","    [2, 1, 0, 2],\n","    [2, 0, 0, 0],\n","])\n","y = np.array([0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0])\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["n_samples, n_features = X.shape\n","\n","classes = np.unique(y)\n","n_classes = classes.shape[0]"]},{"cell_type":"markdown","metadata":{},"source":[" ## 特征选择"]},{"cell_type":"markdown","metadata":{},"source":[" ### 熵"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["0.9709505944546686\n"]}],"source":["values, counts = np.unique(y, return_counts=True)\n","entropy = 0\n","for i in range(n_classes):\n","    p = counts[i] / n_samples\n","    entropy += p * np.log2(p)\n","entropy = -entropy\n","\n","print(entropy)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["0.9709505944546686\n"]}],"source":["def entropy(x):\n","    values, counts = np.unique(x, return_counts=True)\n","    n_classes = values.shape[0]\n","    n_samples = x.shape[0]\n","\n","    entropy_ = 0\n","    for i in range(n_classes):\n","        p = counts[i] / n_samples\n","        entropy_ -= p * np.log2(p)\n","    return entropy_\n","print(entropy(y))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["entropy([0,0,0,1])"]},{"cell_type":"markdown","metadata":{},"source":[" ### 条件熵"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["0.8879430945988998\n"]}],"source":["conditional_entropy = 0\n","splitter_idxs = {}\n","\n","values = X[:, 1]\n","for idx, item in enumerate(values):\n","    splitter_idxs.setdefault(item, [])\n","    splitter_idxs[item].append(idx)\n","\n","for key in splitter_idxs.keys():\n","    x = y[splitter_idxs[key]]\n","    conditional_entropy += len(x) / n_samples * entropy(x)\n","\n","print(conditional_entropy)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["0.8879430945988998\n"]}],"source":["def conditional_entropy(y, x):\n","    n_samples = y.shape[0]\n","\n","    conditional_entropy_ = 0\n","    splitter_idxs = {}\n","\n","    for idx, item in enumerate(x):\n","        splitter_idxs.setdefault(item, [])\n","        splitter_idxs[item].append(idx)\n","\n","    for key in splitter_idxs.keys():\n","        temp = y[splitter_idxs[key]]\n","        conditional_entropy_ += len(temp) / n_samples * entropy(temp)\n","\n","    return conditional_entropy_\n","\n","print(conditional_entropy(y, X[:, 0]))"]},{"cell_type":"markdown","metadata":{},"source":[" ### 信息增益"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["0.08300749985576883\n"]}],"source":["entropy_ = entropy(y)\n","conditional_entropy_ = conditional_entropy(y, X[:, 0])\n","information_gain_ = entropy_ - conditional_entropy_\n","\n","print(information_gain_)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["0.08300749985576883\n"]}],"source":["def information_gain(y, x):\n","    return entropy(y) - conditional_entropy(y, x)\n","\n","print(information_gain(y, X[:, 0]))"]},{"cell_type":"markdown","metadata":{},"source":[" ## 决策树的生成"]},{"source":["### 决策树的生成"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["class Node(object):\n","\n","    # !TODO 类型定义过于宽泛\n","    def __init__(self, feature=None, thresholds=None, sample_idxs=None, n_samples=None, impurity=None, label=None):\n","        # 所以节点均具有的属性\n","        self.n_samples = n_samples\n","        self.impurity = impurity\n","\n","        # 切割节点具有的属性\n","        self.feature = feature\n","        self.children = []\n","        self.thresholds = [] # 每一个进入子节点的条件\n","\n","        # 叶子节点具有的属性\n","        self.label = label"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["class Tree(object):\n","\n","    def __init__(self):\n","        self.root = None"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["feature_idxs = list(range(n_features))"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["decision_tree = Tree()"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["2\n"]}],"source":["max_information_gain = - np.inf\n","selected_feature = None\n","for i in range(n_features):\n","    information_gain_ = information_gain(y, X[:, i])\n","    if information_gain_ > max_information_gain:\n","        max_information_gain = information_gain_\n","        selected_feature = i\n","\n","print(selected_feature)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["feature_idxs.remove(selected_feature)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["decision_tree.root = Node()\n","decision_tree.root.n_samples = n_samples\n","decision_tree.root.impurity = entropy(y)\n","\n","values = X[:, selected_feature]\n","splitter_idxs = {}\n","for idx, item in enumerate(values):\n","    splitter_idxs.setdefault(item, [])\n","    splitter_idxs[item].append(idx)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["for key in splitter_idxs.keys():\n","    child = Node()\n","    child.feature = selected_feature\n","    sample_idxs = splitter_idxs[key]\n","    child.n_samples = len(sample_idxs)\n","    child.impurity = entropy(y[sample_idxs])\n","\n","    decision_tree.root.children.append(child)\n","    decision_tree.root.thresholds.append(key)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["def build(X, y, features=None, samples=None, epsilon=1e-3):\n","    # 为保留原始的 feature 索引\n","    X_ = X[samples, :]\n","    y_ = y[samples]\n","\n","    n_features = len(features)\n","    n_samples = len(samples)\n","\n","    impurity = entropy(y_)\n","\n","    \n","    values, counts = np.unique(y_, return_counts=True)\n","    label = values[np.argmax(counts)]\n","    # 如果特征集 A 为空集，或 D 中所有实例属于同一类\n","    if n_features == 0 or len(np.unique(y_)) == 1:\n","        root = Node(\n","            n_samples=n_samples,\n","            impurity=impurity,\n","            label=label\n","        )\n","        return root\n","\n","    max_information_gain = - np.inf\n","    for feature in features:\n","        information_gain_ = information_gain(y_, X_[:, feature])\n","        if information_gain_ > max_information_gain:\n","            max_information_gain = information_gain_\n","            selected_feature = feature\n","    \n","    features.remove(selected_feature)\n","\n","    # 如果最大信息增益小于阈值 epsilon\n","    if max_information_gain <= epsilon:\n","        root = Node(\n","            n_samples=n_samples,\n","            impurity=impurity,\n","            label=label\n","        )\n","        return root\n","    \n","    root = Node(\n","        feature=selected_feature,\n","        n_samples=n_samples,\n","        impurity=impurity\n","    )\n","\n","    values = X_[:, selected_feature]\n","    splitter_idxs = {}\n","    for idx, item in enumerate(values):\n","        splitter_idxs.setdefault(item, [])\n","        splitter_idxs[item].append(samples[idx])\n","\n","    for key in splitter_idxs.keys():\n","        samples = splitter_idxs[key]\n","        child = build(X, y, features, samples)\n","        threshold = key\n","        root.children.append(child)\n","        root.thresholds.append(threshold)\n","\n","    return root"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["decision_tree.root = build(X, y, list(range(n_features)), list(range(n_samples)))"]},{"source":["### 决策树的输出"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["node 0 is a split node on feature 2 with thresholds [0, 1]\n\tnode 1 is a leaf node with label 1, samples 6 and impurity 0.0\n\tnode 2 is a split node on feature 1 with thresholds [0, 1]\n\t\tnode 3 is a leaf node with label 1, samples 3 and impurity 0.0\n\t\tnode 4 is a leaf node with label 0, samples 6 and impurity 0.0\n"]}],"source":["# https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html\n","\n","stack = [(decision_tree.root, 0)]\n","i = 0\n","while len(stack) > 0:\n","    node, depth = stack.pop()\n","    for child in node.children:\n","        stack.append((child, depth + 1))\n","    if len(node.children) == 0:\n","        print(\"{space}node {node_id} is a leaf node with label {node_label}, samples {node_samples} and impurity {node_impurity}\" \\\n","            .format(space=(depth)*'\\t', node_id=i, node_label=node.label, node_samples=node.n_samples, node_impurity=node.impurity))\n","    else:\n","        print(\"{space}node {node_id} is a split node on feature {node_feature} with thresholds {node_thresholds}\" \\\n","            .format(space=(depth)*'\\t', node_id=i, node_feature=node.feature, node_thresholds=node.thresholds))\n","    i += 1"]},{"source":["### 决策树的预测"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":21}],"source":["X_test = np.array([[0, 0, 0, 0]])\n","y_test = np.array([0])\n","\n","node = decision_tree.root\n","while node.label is None:\n","    selected_feature = node.feature\n","    sample_value = X_test[0][selected_feature]\n","    next_node_idx = node.thresholds.index(sample_value)\n","    node = node.children[next_node_idx]\n","\n","node.label"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["def predict(X, decision_tree):\n","    n_samples = X.shape[0]\n","    y_pred = []\n","    for i in range(n_samples):\n","        node = decision_tree.root\n","        while node.label is None:\n","            selected_feature = node.feature\n","            sample_value = X[i][selected_feature]\n","            next_node_idx = node.thresholds.index(sample_value)\n","            node = node.children[next_node_idx]\n","        y_pred.append(node.label)\n","    return np.array(y_pred)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0])"]},"metadata":{},"execution_count":23}],"source":["predict(X, decision_tree)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0])"]},"metadata":{},"execution_count":26}],"source":["y"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["# !TODO 待完成代码改进\n","#   * 将以上代码抽象化为一个类，并增加绘图函数\n","#   1. 将决策树存储结构简化为二叉树\n","#   2. 使之能够处理连续性协变量\n","#   3. 增加 Gini 指数这一信息增益计算方法\n","#   4. 修改代码使之可以处理回归问题"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"orig_nbformat":2,"kernelspec":{"name":"python388jvsc74a57bd0bc80ae73d0cbfc7e6ba1a6414a6f692fa96249d2d3b92e103158da0cb88d3364","display_name":"Python 3.8.8 64-bit ('base': conda)"}}}